{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import radiomics\n",
    "from radiomics import featureextractor\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import SimpleITK as sitk\n",
    "from __future__ import print_function\n",
    "import yaml\n",
    "import csv\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m destination_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/gabrielasimon/Desktop/lab-iacd/pre_processing/LIDC_XML_only/renamed_files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Chamar a função para mover e renomear os arquivos\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mmove_and_rename_xml_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36mmove_and_rename_xml_files\u001b[0;34m(base_dir, folders, destination_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove_and_rename_xml_files\u001b[39m(base_dir, folders, destination_dir):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(destination_dir):\n\u001b[1;32m      3\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(destination_dir)\n\u001b[1;32m      5\u001b[0m     file_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def move_and_rename_xml_files(base_dir, folders, destination_dir):\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    file_counter = 1\n",
    "\n",
    "    # Iterar pelas pastas originais\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "\n",
    "        # Iterar pelos arquivos na pasta\n",
    "        for xml_file in os.listdir(folder_path):\n",
    "            if xml_file.endswith(\".xml\"):\n",
    "                source_path = os.path.join(folder_path, xml_file)\n",
    "                destination_path = os.path.join(destination_dir, f\"{file_counter}.xml\")\n",
    "                \n",
    "                # Mover e renomear o arquivo\n",
    "                shutil.move(source_path, destination_path)\n",
    "                print(f\"Arquivo {xml_file} movido e renomeado para {file_counter}.xml\")\n",
    "                \n",
    "                file_counter += 1\n",
    "    print(\"Concluido com sucesso!\")\n",
    "\n",
    "# Diretório base onde estão as pastas\n",
    "base_dir = \"LIDC_XML_only/tcia-lidc-xml\"\n",
    "folders = ['157', '185', '186', '187', '188', '189']\n",
    "\n",
    "# Diretório de destino para os arquivos renomeados\n",
    "destination_dir = \"renamed_files\"\n",
    "\n",
    "# Chamar a função para mover e renomear os arquivos\n",
    "move_and_rename_xml_files(base_dir, folders, destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UIDs salvos em uids.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_uids_from_xml(xml_file):\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Extrair StudyInstanceUID e SeriesInstanceUID\n",
    "        ns = {'ns': 'http://www.nih.gov'}  # Namespace no XML\n",
    "        study_uid_element = root.find('.//ns:StudyInstanceUID', ns)\n",
    "        series_uid_element = root.find('.//ns:SeriesInstanceUid', ns)\n",
    "        \n",
    "        if study_uid_element is None or series_uid_element is None:\n",
    "            return None, None  # Ignorar arquivos sem as tags\n",
    "        \n",
    "        study_uid = study_uid_element.text\n",
    "        series_uid = series_uid_element.text\n",
    "        \n",
    "        return study_uid, series_uid\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Erro ao analisar o arquivo XML {xml_file}: {e}\")\n",
    "        return None, None  # Retorna None se houver erro ao processar o XML\n",
    "\n",
    "def iterate_xml_files_and_store_uids_csv(base_dir, output_file):\n",
    "    # Abrir arquivo CSV para escrita\n",
    "    with open(output_file, mode='w', newline='') as csv_file:\n",
    "        fieldnames = ['Arquivo', 'StudyInstanceUID', 'SeriesInstanceUID']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        \n",
    "        # Escrever o cabeçalho\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Iterar pelos arquivos XML na pasta\n",
    "        for xml_file in os.listdir(base_dir):  # Usa base_dir aqui\n",
    "            if xml_file.endswith(\".xml\"):\n",
    "                xml_path = os.path.join(base_dir, xml_file)\n",
    "                \n",
    "                study_uid, series_uid = extract_uids_from_xml(xml_path)\n",
    "                \n",
    "                # Só escrever se os UIDs foram encontrados\n",
    "                if study_uid and series_uid:\n",
    "                    writer.writerow({\n",
    "                        'Arquivo': xml_file,\n",
    "                        'StudyInstanceUID': study_uid,\n",
    "                        'SeriesInstanceUID': series_uid\n",
    "                    })\n",
    "\n",
    "# Diretório base onde estão os arquivos renomeados\n",
    "base_dir = \"LIDC_XML_only/renamed_files\"\n",
    "output_file = \"uids.csv\"\n",
    "\n",
    "# Chamar a função para iterar e guardar os UIDs em um CSV\n",
    "iterate_xml_files_and_store_uids_csv(base_dir, output_file)\n",
    "\n",
    "print(f\"UIDs salvos em {output_file}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mascara dos arquivos xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mask_from_xml(dicom_image, xml_file):\n",
    "\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    size = dicom_image.GetSize()\n",
    "    mask = np.zeros(size, dtype=np.uint8)\n",
    "    \n",
    "    for lesion in root.findall('.//lesion'):\n",
    "        for roi in lesion.findall('.//roi'):\n",
    "            for edgeMap in roi.findall('.//edgeMap'):\n",
    "                x_coord = edgeMap.find('xCoord')\n",
    "                y_coord = edgeMap.find('yCoord')\n",
    "                \n",
    "                if x_coord is not None and y_coord is not None:\n",
    "                    x = int(x_coord.text)\n",
    "                    y = int(y_coord.text)\n",
    "                    \n",
    "                    if 0 <= x < size[0] and 0 <= y < size[1]: \n",
    "                        mask[y, x] = 1\n",
    "                else:\n",
    "                    print(\"Coordenadas não encontradas em edgeMap.\")\n",
    "\n",
    "    mask_image = sitk.GetImageFromArray(mask)\n",
    "    mask_image.CopyInformation(dicom_image)\n",
    "    \n",
    "    return mask_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extração de features dos arquivos dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de imagem habilitados: {'Original': {}}\n",
      "Features habilitadas: {'firstorder': [], 'glcm': [], 'gldm': [], 'glrlm': [], 'glszm': [], 'ngtdm': [], 'shape': []}\n",
      "Configurações atuais: {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 23, 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True, 'binWidth': 25, 'enableCExtensions': True}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pre_processing/uids.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 82\u001b[0m\n\u001b[1;32m     78\u001b[0m     results\u001b[38;5;241m.\u001b[39mto_csv(outputFilepath, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na_rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGravação do CSV completa\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m \u001b[43mfeature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mfeature_extraction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures habilitadas:\u001b[39m\u001b[38;5;124m'\u001b[39m, extractor\u001b[38;5;241m.\u001b[39menabledFeatures)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfigurações atuais:\u001b[39m\u001b[38;5;124m'\u001b[39m, extractor\u001b[38;5;241m.\u001b[39msettings)\n\u001b[0;32m---> 29\u001b[0m uids_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_csv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patient_folder \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(base_dir):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pre_processing/uids.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "def feature_extraction():\n",
    "    base_dir = r'pre_processing/LIDC-IDRI-files'  # pasta com subpastas de pacientes\n",
    "    outPath = r'pre_processing/feature_extraction'  \n",
    "    xml_csv_path = r'/Users/gabrielasimon/Desktop/LAB-IACD-24-25/pre_processing/uids.csv'  # CSV com os UIDs\n",
    "\n",
    "    # ver se o diretório de saída existe\n",
    "    if not os.path.exists(outPath):\n",
    "        os.makedirs(outPath)\n",
    "\n",
    "    outputFilepath = os.path.join(outPath, 'radiomics_features.csv')\n",
    "\n",
    "    params = os.path.join(outPath, 'exampleSettings', 'Params.yaml')\n",
    "\n",
    "    if os.path.isfile(params):\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(params)\n",
    "    else:\n",
    "        settings = {\n",
    "            'binWidth': 25,\n",
    "            'resampledPixelSpacing': None,\n",
    "            'interpolator': sitk.sitkBSpline,\n",
    "            'enableCExtensions': True\n",
    "        }\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(**settings)\n",
    "\n",
    "    print('Tipos de imagem habilitados:', extractor.enabledImagetypes)\n",
    "    print('Features habilitadas:', extractor.enabledFeatures)\n",
    "    print('Configurações atuais:', extractor.settings)\n",
    "\n",
    "    uids_df = pd.read_csv(xml_csv_path)\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for patient_folder in os.listdir(base_dir):\n",
    "        patient_path = os.path.join(base_dir, patient_folder)\n",
    "        \n",
    "        if os.path.isdir(patient_path):\n",
    "            dicom_files = [os.path.join(patient_path, f) for f in os.listdir(patient_path) if f.endswith('.dcm')]\n",
    "\n",
    "            if len(dicom_files) > 0:\n",
    "                imageFilepath = dicom_files[0]  \n",
    "\n",
    "                # XML correspondente no CSV\n",
    "                dicom_metadata = sitk.ReadImage(imageFilepath)\n",
    "                study_uid = dicom_metadata.GetMetaData(\"0020|000D\")  \n",
    "                series_uid = dicom_metadata.GetMetaData(\"0020|000E\")  \n",
    "\n",
    "                xml_row = uids_df[(uids_df['StudyInstanceUID'] == study_uid) & \n",
    "                                  (uids_df['SeriesInstanceUID'] == series_uid)]\n",
    "                \n",
    "                if not xml_row.empty:\n",
    "                    xml_file = xml_row['Arquivo'].values[0]\n",
    "                    xml_file_path = os.path.join(base_dir, 'path_to_xml_files', xml_file)\n",
    "\n",
    "                    try:\n",
    "                        mask_image = create_mask_from_xml(dicom_metadata, xml_file_path)\n",
    "\n",
    "                        print(f\"Processando Paciente: {patient_folder}, Imagem: {os.path.basename(imageFilepath)}, Máscara: {os.path.basename(xml_file)}\")\n",
    "\n",
    "                        try:\n",
    "                            # extração de features\n",
    "                            result = pd.Series(extractor.execute(imageFilepath, mask_image))\n",
    "                            result['PatientID'] = patient_folder\n",
    "                            result['Image'] = os.path.basename(imageFilepath)\n",
    "                            result['Mask'] = os.path.basename(xml_file)\n",
    "                            \n",
    "                            results = results.append(result, ignore_index=True)\n",
    "                            \n",
    "                        except Exception:\n",
    "                            print(f'FALHA NA EXTRAÇÃO DE FEATURES para o paciente {patient_folder}: {e}')\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao criar a máscara para o paciente {patient_folder}: {e}\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"XML correspondente não encontrado para o paciente {patient_folder}. Pulando.\")\n",
    "\n",
    "    print('Extração completa, escrevendo CSV')\n",
    "    results.to_csv(outputFilepath, index=False, na_rep='NaN')\n",
    "    print('Gravação do CSV completa')\n",
    "\n",
    "\n",
    "feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
