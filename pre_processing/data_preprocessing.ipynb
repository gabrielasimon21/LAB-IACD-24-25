{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import radiomics\n",
    "from radiomics import featureextractor\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import SimpleITK as sitk\n",
    "from __future__ import print_function\n",
    "import logging\n",
    "import csv\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m destination_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/gabrielasimon/Desktop/lab-iacd/pre_processing/LIDC_XML_only/renamed_files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Chamar a função para mover e renomear os arquivos\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mmove_and_rename_xml_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36mmove_and_rename_xml_files\u001b[0;34m(base_dir, folders, destination_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove_and_rename_xml_files\u001b[39m(base_dir, folders, destination_dir):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(destination_dir):\n\u001b[1;32m      3\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(destination_dir)\n\u001b[1;32m      5\u001b[0m     file_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def move_and_rename_xml_files(base_dir, folders, destination_dir):\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    file_counter = 1\n",
    "\n",
    "    # Iterar pelas pastas originais\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "\n",
    "        # Iterar pelos arquivos na pasta\n",
    "        for xml_file in os.listdir(folder_path):\n",
    "            if xml_file.endswith(\".xml\"):\n",
    "                source_path = os.path.join(folder_path, xml_file)\n",
    "                destination_path = os.path.join(destination_dir, f\"{file_counter}.xml\")\n",
    "                \n",
    "                # Mover e renomear o arquivo\n",
    "                shutil.move(source_path, destination_path)\n",
    "                print(f\"Arquivo {xml_file} movido e renomeado para {file_counter}.xml\")\n",
    "                \n",
    "                file_counter += 1\n",
    "    print(\"Concluido com sucesso!\")\n",
    "\n",
    "# Diretório base onde estão as pastas\n",
    "base_dir = \"LIDC_XML_only/tcia-lidc-xml\"\n",
    "folders = ['157', '185', '186', '187', '188', '189']\n",
    "\n",
    "# Diretório de destino para os arquivos renomeados\n",
    "destination_dir = \"renamed_files\"\n",
    "\n",
    "# Chamar a função para mover e renomear os arquivos\n",
    "move_and_rename_xml_files(base_dir, folders, destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UIDs salvos em uids.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_uids_from_xml(xml_file):\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Extrair StudyInstanceUID e SeriesInstanceUID\n",
    "        ns = {'ns': 'http://www.nih.gov'}  # Namespace no XML\n",
    "        study_uid_element = root.find('.//ns:StudyInstanceUID', ns)\n",
    "        series_uid_element = root.find('.//ns:SeriesInstanceUid', ns)\n",
    "        \n",
    "        if study_uid_element is None or series_uid_element is None:\n",
    "            return None, None  # Ignorar arquivos sem as tags\n",
    "        \n",
    "        study_uid = study_uid_element.text\n",
    "        series_uid = series_uid_element.text\n",
    "        \n",
    "        return study_uid, series_uid\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Erro ao analisar o arquivo XML {xml_file}: {e}\")\n",
    "        return None, None  # Retorna None se houver erro ao processar o XML\n",
    "\n",
    "def iterate_xml_files_and_store_uids_csv(base_dir, output_file):\n",
    "    # Abrir arquivo CSV para escrita\n",
    "    with open(output_file, mode='w', newline='') as csv_file:\n",
    "        fieldnames = ['Arquivo', 'StudyInstanceUID', 'SeriesInstanceUID']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        \n",
    "        # Escrever o cabeçalho\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Iterar pelos arquivos XML na pasta\n",
    "        for xml_file in os.listdir(base_dir):  # Usa base_dir aqui\n",
    "            if xml_file.endswith(\".xml\"):\n",
    "                xml_path = os.path.join(base_dir, xml_file)\n",
    "                \n",
    "                study_uid, series_uid = extract_uids_from_xml(xml_path)\n",
    "                \n",
    "                # Só escrever se os UIDs foram encontrados\n",
    "                if study_uid and series_uid:\n",
    "                    writer.writerow({\n",
    "                        'Arquivo': xml_file,\n",
    "                        'StudyInstanceUID': study_uid,\n",
    "                        'SeriesInstanceUID': series_uid\n",
    "                    })\n",
    "\n",
    "# Diretório base onde estão os arquivos renomeados\n",
    "base_dir = \"LIDC_XML_only/renamed_files\"\n",
    "output_file = \"uids.csv\"\n",
    "\n",
    "# Chamar a função para iterar e guardar os UIDs em um CSV\n",
    "iterate_xml_files_and_store_uids_csv(base_dir, output_file)\n",
    "\n",
    "print(f\"UIDs salvos em {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mascara dos arquivos xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mask_from_xml(dicom_image, xml_file):\n",
    "    # Ler o arquivo XML\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Obter as dimensões da imagem DICOM\n",
    "    size = dicom_image.GetSize()  # (Width, Height, Depth) para 3D ou (Width, Height) para 2D\n",
    "    if len(size) == 3:\n",
    "        mask = np.zeros(size, dtype=np.uint8)  # Máscara 3D\n",
    "    else:\n",
    "        mask = np.zeros((size[1], size[0]), dtype=np.uint8)  # Máscara 2D\n",
    "    \n",
    "    # Processar o XML para extrair as coordenadas dos nódulos\n",
    "    for lesion in root.findall('.//lesion'):\n",
    "        for roi in lesion.findall('.//roi'):\n",
    "            for edgeMap in roi.findall('.//edgeMap'):\n",
    "                x = int(edgeMap.find('xCoord').text)\n",
    "                y = int(edgeMap.find('yCoord').text)\n",
    "                \n",
    "                # Verificar se é 2D ou 3D (DICOM volume)\n",
    "                if len(size) == 3:\n",
    "                    z = int(roi.find('imageZposition').text)  # Exemplo de Z vindo do XML\n",
    "                    mask[y, x, z] = 1  # Nota: y primeiro, depois x, depois z\n",
    "                else:\n",
    "                    mask[y, x] = 1  # Para imagens 2D\n",
    "\n",
    "    # Converter o numpy array para uma imagem SimpleITK\n",
    "    mask_image = sitk.GetImageFromArray(mask)\n",
    "    \n",
    "    # Configurar a geometria da máscara para ser a mesma da imagem DICOM\n",
    "    mask_image.CopyInformation(dicom_image)\n",
    "    \n",
    "    return mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mask_from_xml(dicom_image, xml_file):\n",
    "    # Função para criar máscara do XML (similar à função que você postou antes)\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    size = dicom_image.GetSize()\n",
    "    mask = np.zeros(size, dtype=np.uint8)\n",
    "    \n",
    "    for lesion in root.findall('.//lesion'):\n",
    "        for roi in lesion.findall('.//roi'):\n",
    "            for edgeMap in roi.findall('.//edgeMap'):\n",
    "                x = int(edgeMap.find('xCoord').text)\n",
    "                y = int(edgeMap.find('yCoord').text)\n",
    "                mask[y, x] = 1\n",
    "    \n",
    "    mask_image = sitk.GetImageFromArray(mask)\n",
    "    mask_image.CopyInformation(dicom_image)\n",
    "    \n",
    "    return mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_xml(dicom_image, xml_file):\n",
    "    # Função para criar máscara do XML (similar à função que você postou antes)\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    size = dicom_image.GetSize()\n",
    "    mask = np.zeros(size, dtype=np.uint8)\n",
    "    \n",
    "    for lesion in root.findall('.//lesion'):\n",
    "        for roi in lesion.findall('.//roi'):\n",
    "            for edgeMap in roi.findall('.//edgeMap'):\n",
    "                x = int(edgeMap.find('xCoord').text)\n",
    "                y = int(edgeMap.find('yCoord').text)\n",
    "                mask[y, x] = 1\n",
    "    \n",
    "    mask_image = sitk.GetImageFromArray(mask)\n",
    "    mask_image.CopyInformation(dicom_image)\n",
    "    \n",
    "    return mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gabrielasimon/Desktop/lab-iacd/pre_processing/pre_processing/feature_extraction.csv/pyrad_log.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m     results\u001b[38;5;241m.\u001b[39mto_csv(outputFilepath, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na_rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGravação do CSV completa\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[43mfeature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mfeature_extraction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Configurar logging\u001b[39;00m\n\u001b[1;32m     11\u001b[0m rLogger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradiomics\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m handler\u001b[38;5;241m.\u001b[39msetFormatter(logging\u001b[38;5;241m.\u001b[39mFormatter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m rLogger\u001b[38;5;241m.\u001b[39maddHandler(handler)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/logging/__init__.py:1146\u001b[0m, in \u001b[0;36mFileHandler.__init__\u001b[0;34m(self, filename, mode, encoding, delay, errors)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1146\u001b[0m     StreamHandler\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/logging/__init__.py:1175\u001b[0m, in \u001b[0;36mFileHandler._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m    Open the current base file with the (original) mode and encoding.\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m    Return the resulting stream.\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseFilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gabrielasimon/Desktop/lab-iacd/pre_processing/pre_processing/feature_extraction.csv/pyrad_log.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "def feature_extraction():\n",
    "    base_dir = r'pre_processing/LIDC-IDRI-files'  # Pasta com subpastas de pacientes\n",
    "    outPath = r'pre_processing/feature_extraction.csv'  # Caminho de saída\n",
    "    xml_csv_path = r'pre_processing/uids.csv'  # Caminho para o CSV com os UIDs\n",
    "\n",
    "    outputFilepath = os.path.join(outPath, 'radiomics_features.csv')\n",
    "    progress_filename = os.path.join(outPath, 'pyrad_log.txt')\n",
    "    params = os.path.join(outPath, 'exampleSettings', 'Params.yaml')\n",
    "\n",
    "    # Configurar logging\n",
    "    rLogger = logging.getLogger('radiomics')\n",
    "    handler = logging.FileHandler(filename=progress_filename, mode='w')\n",
    "    handler.setFormatter(logging.Formatter('%(levelname)s:%(name)s: %(message)s'))\n",
    "    rLogger.addHandler(handler)\n",
    "    logger = rLogger.getChild('batch')\n",
    "    radiomics.setVerbosity(logging.INFO)\n",
    "    logger.info('Versão do PyRadiomics: %s', radiomics.__version__)\n",
    "\n",
    "    # Carregar parâmetros\n",
    "    if os.path.isfile(params):\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(params)\n",
    "    else:\n",
    "        settings = {\n",
    "            'binWidth': 25,\n",
    "            'resampledPixelSpacing': None,\n",
    "            'interpolator': sitk.sitkBSpline,\n",
    "            'enableCExtensions': True\n",
    "        }\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(**settings)\n",
    "\n",
    "    logger.info('Tipos de imagem habilitados: %s', extractor.enabledImagetypes)\n",
    "    logger.info('Features habilitadas: %s', extractor.enabledFeatures)\n",
    "    logger.info('Configurações atuais: %s', extractor.settings)\n",
    "\n",
    "    # Carregar o CSV com os UIDs\n",
    "    uids_df = pd.read_csv(xml_csv_path)\n",
    "\n",
    "    # Inicializar um DataFrame para armazenar os resultados\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    # Iterar pelas subpastas dos pacientes\n",
    "    for patient_folder in os.listdir(base_dir):\n",
    "        patient_path = os.path.join(base_dir, patient_folder)\n",
    "        \n",
    "        if os.path.isdir(patient_path):\n",
    "            dicom_files = [os.path.join(patient_path, f) for f in os.listdir(patient_path) if f.endswith('.dcm')]\n",
    "\n",
    "            if len(dicom_files) > 0:\n",
    "                imageFilepath = dicom_files[0]  # Usando o primeiro DICOM da pasta\n",
    "\n",
    "                # Encontrar o XML correspondente no CSV\n",
    "                dicom_metadata = sitk.ReadImage(imageFilepath)\n",
    "                study_uid = dicom_metadata.GetMetaData(\"0020|000D\")  # StudyInstanceUID do DICOM\n",
    "                series_uid = dicom_metadata.GetMetaData(\"0020|000E\")  # SeriesInstanceUID do DICOM\n",
    "\n",
    "                xml_row = uids_df[(uids_df['StudyInstanceUID'] == study_uid) & \n",
    "                                  (uids_df['SeriesInstanceUID'] == series_uid)]\n",
    "                \n",
    "                if not xml_row.empty:\n",
    "                    xml_file = xml_row['Arquivo'].values[0]\n",
    "                    xml_file_path = os.path.join(base_dir, 'path_to_xml_files', xml_file)\n",
    "\n",
    "                    # Criar a máscara a partir do XML\n",
    "                    mask_image = create_mask_from_xml(dicom_metadata, xml_file_path)\n",
    "\n",
    "                    logger.info(\"Processando Paciente: %s, Imagem: %s, Máscara: %s\", \n",
    "                                patient_folder, os.path.basename(imageFilepath), os.path.basename(xml_file))\n",
    "\n",
    "                    try:\n",
    "                        # Executar a extração de features\n",
    "                        result = pd.Series(extractor.execute(imageFilepath, mask_image))\n",
    "                        result['PatientID'] = patient_folder\n",
    "                        result['Image'] = os.path.basename(imageFilepath)\n",
    "                        result['Mask'] = os.path.basename(xml_file)\n",
    "                        \n",
    "                        # Adicionar as features ao DataFrame de resultados\n",
    "                        results = results.append(result, ignore_index=True)\n",
    "                        \n",
    "                    except Exception:\n",
    "                        logger.error('FALHA NA EXTRAÇÃO DE FEATURES:', exc_info=True)\n",
    "\n",
    "    logger.info('Extração completa, escrevendo CSV')\n",
    "    results.to_csv(outputFilepath, index=False, na_rep='NaN')\n",
    "    logger.info('Gravação do CSV completa')\n",
    "\n",
    "feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gabrielasimon/Desktop/lab-iacd/pre_processing/pre_processing/feature_extraction.csv/pyrad_log.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m     results\u001b[38;5;241m.\u001b[39mto_csv(outputFilepath, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na_rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     91\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGravação do CSV completa\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[43mfeature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mfeature_extraction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Configurar logging\u001b[39;00m\n\u001b[1;32m     11\u001b[0m rLogger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradiomics\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m handler\u001b[38;5;241m.\u001b[39msetFormatter(logging\u001b[38;5;241m.\u001b[39mFormatter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m rLogger\u001b[38;5;241m.\u001b[39maddHandler(handler)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/logging/__init__.py:1146\u001b[0m, in \u001b[0;36mFileHandler.__init__\u001b[0;34m(self, filename, mode, encoding, delay, errors)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1146\u001b[0m     StreamHandler\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/logging/__init__.py:1175\u001b[0m, in \u001b[0;36mFileHandler._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m    Open the current base file with the (original) mode and encoding.\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m    Return the resulting stream.\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseFilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gabrielasimon/Desktop/lab-iacd/pre_processing/pre_processing/feature_extraction.csv/pyrad_log.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def feature_extraction():\n",
    "    base_dir = r'pre_processing/LIDC-IDRI-files'  # Pasta com subpastas de pacientes\n",
    "    outPath = r'pre_processing/feature_extraction.csv'  # Caminho de saída\n",
    "    xml_csv_path = r'pre_processing/uids.csv'  # Caminho para o CSV com os UIDs\n",
    "\n",
    "    outputFilepath = os.path.join(outPath, 'radiomics_features.csv')\n",
    "    progress_filename = os.path.join(outPath, 'pyrad_log.txt')\n",
    "    params = os.path.join(outPath, 'exampleSettings', 'Params.yaml')\n",
    "\n",
    "    # Configurar logging\n",
    "    rLogger = logging.getLogger('radiomics')\n",
    "    handler = logging.FileHandler(filename=progress_filename, mode='w')\n",
    "    handler.setFormatter(logging.Formatter('%(levelname)s:%(name)s: %(message)s'))\n",
    "    rLogger.addHandler(handler)\n",
    "    logger = rLogger.getChild('batch')\n",
    "    radiomics.setVerbosity(logging.INFO)\n",
    "    logger.info('Versão do PyRadiomics: %s', radiomics.__version__)\n",
    "\n",
    "    # Carregar parâmetros\n",
    "    if os.path.isfile(params):\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(params)\n",
    "    else:\n",
    "        settings = {\n",
    "            'binWidth': 25,\n",
    "            'resampledPixelSpacing': None,\n",
    "            'interpolator': sitk.sitkBSpline,\n",
    "            'enableCExtensions': True\n",
    "        }\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(**settings)\n",
    "\n",
    "    logger.info('Tipos de imagem habilitados: %s', extractor.enabledImagetypes)\n",
    "    logger.info('Features habilitadas: %s', extractor.enabledFeatures)\n",
    "    logger.info('Configurações atuais: %s', extractor.settings)\n",
    "\n",
    "    # Carregar o CSV com os UIDs\n",
    "    uids_df = pd.read_csv(xml_csv_path)\n",
    "\n",
    "    # Inicializar um DataFrame para armazenar os resultados\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    # Iterar pelas subpastas dos pacientes\n",
    "    for patient_folder in os.listdir(base_dir):\n",
    "        patient_path = os.path.join(base_dir, patient_folder)\n",
    "        \n",
    "        if os.path.isdir(patient_path):\n",
    "            dicom_files = [os.path.join(patient_path, f) for f in os.listdir(patient_path) if f.endswith('.dcm')]\n",
    "\n",
    "            if len(dicom_files) > 0:\n",
    "                imageFilepath = dicom_files[0]  # Usando o primeiro DICOM da pasta\n",
    "\n",
    "                # Encontrar o XML correspondente no CSV\n",
    "                dicom_metadata = sitk.ReadImage(imageFilepath)\n",
    "                study_uid = dicom_metadata.GetMetaData(\"0020|000D\")  # StudyInstanceUID do DICOM\n",
    "                series_uid = dicom_metadata.GetMetaData(\"0020|000E\")  # SeriesInstanceUID do DICOM\n",
    "\n",
    "                xml_row = uids_df[(uids_df['StudyInstanceUID'] == study_uid) & \n",
    "                                  (uids_df['SeriesInstanceUID'] == series_uid)]\n",
    "                \n",
    "                if not xml_row.empty:\n",
    "                    xml_file = xml_row['Arquivo'].values[0]\n",
    "                    xml_file_path = os.path.join(base_dir, 'path_to_xml_files', xml_file)\n",
    "\n",
    "                    try:\n",
    "                        # Criar a máscara a partir do XML\n",
    "                        mask_image = create_mask_from_xml(dicom_metadata, xml_file_path)\n",
    "\n",
    "                        logger.info(\"Processando Paciente: %s, Imagem: %s, Máscara: %s\", \n",
    "                                    patient_folder, os.path.basename(imageFilepath), os.path.basename(xml_file))\n",
    "\n",
    "                        try:\n",
    "                            # Executar a extração de features\n",
    "                            result = pd.Series(extractor.execute(imageFilepath, mask_image))\n",
    "                            result['PatientID'] = patient_folder\n",
    "                            result['Image'] = os.path.basename(imageFilepath)\n",
    "                            result['Mask'] = os.path.basename(xml_file)\n",
    "                            \n",
    "                            # Adicionar as features ao DataFrame de resultados\n",
    "                            results = results.append(result, ignore_index=True)\n",
    "                            \n",
    "                        except Exception:\n",
    "                            logger.error('FALHA NA EXTRAÇÃO DE FEATURES:', exc_info=True)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Erro ao criar a máscara para o paciente {patient_folder}: {e}\")\n",
    "\n",
    "                else:\n",
    "                    logger.warning(f\"XML correspondente não encontrado para o paciente {patient_folder}. Pulando.\")\n",
    "\n",
    "    logger.info('Extração completa, escrevendo CSV')\n",
    "    results.to_csv(outputFilepath, index=False, na_rep='NaN')\n",
    "    logger.info('Gravação do CSV completa')\n",
    "\n",
    "feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_extraction():\n",
    "    base_dir = r'pre_processing/LIDC-IDRI-files'  # Pasta com subpastas de pacientes\n",
    "    outPath = r'pre_processing/feature_extraction'  # Corrigido: deve ser um diretório\n",
    "    xml_csv_path = r'pre_processing/uids.csv'  # Caminho para o CSV com os UIDs\n",
    "\n",
    "    # Certifique-se de que o diretório de saída existe\n",
    "    if not os.path.exists(outPath):\n",
    "        os.makedirs(outPath)\n",
    "\n",
    "    outputFilepath = os.path.join(outPath, 'radiomics_features.csv')\n",
    "    progress_filename = os.path.join(outPath, 'pyrad_log.txt')\n",
    "    params = os.path.join(outPath, 'exampleSettings', 'Params.yaml')\n",
    "\n",
    "    # Configurar logging\n",
    "    rLogger = logging.getLogger('radiomics')\n",
    "    handler = logging.FileHandler(filename=progress_filename, mode='w')\n",
    "    handler.setFormatter(logging.Formatter('%(levelname)s:%(name)s: %(message)s'))\n",
    "    rLogger.addHandler(handler)\n",
    "    logger = rLogger.getChild('batch')\n",
    "    featureextractor.setVerbosity(logging.INFO)\n",
    "    logger.info('Versão do PyRadiomics: %s', featureextractor.__version__)\n",
    "\n",
    "    # Carregar parâmetros\n",
    "    if os.path.isfile(params):\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(params)\n",
    "    else:\n",
    "        settings = {\n",
    "            'binWidth': 25,\n",
    "            'resampledPixelSpacing': None,\n",
    "            'interpolator': sitk.sitkBSpline,\n",
    "            'enableCExtensions': True\n",
    "        }\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(**settings)\n",
    "\n",
    "    logger.info('Tipos de imagem habilitados: %s', extractor.enabledImagetypes)\n",
    "    logger.info('Features habilitadas: %s', extractor.enabledFeatures)\n",
    "    logger.info('Configurações atuais: %s', extractor.settings)\n",
    "\n",
    "    # Carregar o CSV com os UIDs\n",
    "    uids_df = pd.read_csv(xml_csv_path)\n",
    "\n",
    "    # Inicializar um DataFrame para armazenar os resultados\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    # Iterar pelas subpastas dos pacientes\n",
    "    for patient_folder in os.listdir(base_dir):\n",
    "        patient_path = os.path.join(base_dir, patient_folder)\n",
    "        \n",
    "        if os.path.isdir(patient_path):\n",
    "            dicom_files = [os.path.join(patient_path, f) for f in os.listdir(patient_path) if f.endswith('.dcm')]\n",
    "\n",
    "            if len(dicom_files) > 0:\n",
    "                imageFilepath = dicom_files[0]  # Usando o primeiro DICOM da pasta\n",
    "\n",
    "                # Encontrar o XML correspondente no CSV\n",
    "                dicom_metadata = sitk.ReadImage(imageFilepath)\n",
    "                study_uid = dicom_metadata.GetMetaData(\"0020|000D\")  # StudyInstanceUID do DICOM\n",
    "                series_uid = dicom_metadata.GetMetaData(\"0020|000E\")  # SeriesInstanceUID do DICOM\n",
    "\n",
    "                xml_row = uids_df[(uids_df['StudyInstanceUID'] == study_uid) & \n",
    "                                  (uids_df['SeriesInstanceUID'] == series_uid)]\n",
    "                \n",
    "                if not xml_row.empty:\n",
    "                    xml_file = xml_row['Arquivo'].values[0]\n",
    "                    xml_file_path = os.path.join(base_dir, 'path_to_xml_files', xml_file)\n",
    "\n",
    "                    try:\n",
    "                        # Criar a máscara a partir do XML\n",
    "                        mask_image = create_mask_from_xml(dicom_metadata, xml_file_path)\n",
    "\n",
    "                        logger.info(\"Processando Paciente: %s, Imagem: %s, Máscara: %s\", \n",
    "                                    patient_folder, os.path.basename(imageFilepath), os.path.basename(xml_file))\n",
    "\n",
    "                        try:\n",
    "                            # Executar a extração de features\n",
    "                            result = pd.Series(extractor.execute(imageFilepath, mask_image))\n",
    "                            result['PatientID'] = patient_folder\n",
    "                            result['Image'] = os.path.basename(imageFilepath)\n",
    "                            result['Mask'] = os.path.basename(xml_file)\n",
    "                            \n",
    "                            # Adicionar as features ao DataFrame de resultados\n",
    "                            results = results.append(result, ignore_index=True)\n",
    "                            \n",
    "                        except Exception:\n",
    "                            logger.error('FALHA NA EXTRAÇÃO DE FEATURES:', exc_info=True)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Erro ao criar a máscara para o paciente {patient_folder}: {e}\")\n",
    "\n",
    "                else:\n",
    "                    logger.warning(f\"XML correspondente não encontrado para o paciente {patient_folder}. Pulando.\")\n",
    "\n",
    "    logger.info('Extração completa, escrevendo CSV')\n",
    "    results.to_csv(outputFilepath, index=False, na_rep='NaN')\n",
    "    logger.info('Gravação do CSV completa')\n",
    "\n",
    "feature_extraction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
